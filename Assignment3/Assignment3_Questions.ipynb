{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Goals\n",
    "In Assignment 2, we learned how to construct networks of spiking neurons and propagate information through a network of fixed weights. In this assignment, you will learn how to train network weights for a given task using brain-inspired learning rules.\n",
    "\n",
    "Let's import all the libraries required for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Training a Network\n",
    "\n",
    "## 1a. \n",
    "What is the purpose of a learning algorithm? In other words, what does a learning algorithm dictate, and what is the objective of it?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1a. \n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. \n",
    "Categorize and explain the various learning algorithms w.r.t. biological plausibility. Can you explain the tradeoffs involved with the different learning rules? *Hint: Think computational advantages and disadvantages of biological plausibility.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1b.\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Hebbian Learning\n",
    "\n",
    "## 2a.\n",
    "\n",
    "In this exercise, you will implement the hebbian learning rule to solve AND Gate. First, we need to create a helper function to generate the training data. The function should return lists of tuples where each tuple comprises of numpy arrays of rate-coded inputs and the corresponding rate-coded output. \n",
    "\n",
    "Below is the function to generate the training data. Fill the components to return the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genANDTrainData(snn_timestep):\n",
    "    \"\"\" \n",
    "    Function to generate the training data for AND \n",
    "        Args:\n",
    "            snn_timestep (int): timesteps for SNN simulation\n",
    "        Return:\n",
    "            train_data (list): list of tuples where each tuple comprises of numpy arrays of rate-coded inputs and output\n",
    "        \n",
    "        Write the expressions for encoding 0 and 1. Then append all 4 cases of AND gate to the list train_data\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize an empty list for train data\n",
    "    train_data = []\n",
    "    \n",
    "    #encode 0. Numpy random choice function might be useful here. \n",
    "\n",
    "    \n",
    "    #encode 1. Numpy random choice function might be useful here. \n",
    "\n",
    "    \n",
    "    #Append all 4 cases of AND gate to train_data. Numpy stack operation might be useful here. \n",
    "\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. \n",
    "We will use the implementation of the network from assignment 2 to create an SNN comprising of one input layer and one output layer. Can you explain algorithmically, how you can use this simple architecture to learn AND gate. Your algorithm should comprise of encoding, forward propagation, network training, and decoding steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2b. \n",
    "\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNN has already been implemented for you. You do not need to do anything here. Just understand the implementation so that you can use it in the later parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeurons:\n",
    "    \"\"\" \n",
    "        Define Leaky Integrate-and-Fire Neuron Layer \n",
    "        This class is complete. You do not need to do anything here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimension, vdecay, vth):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimension (int): Number of LIF neurons in the layer\n",
    "            vdecay (float): voltage decay of LIF neurons\n",
    "            vth (float): voltage threshold of LIF neurons\n",
    "        \n",
    "        \"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.vdecay = vdecay\n",
    "        self.vth = vth\n",
    "\n",
    "        # Initialize LIF neuron states\n",
    "        self.volt = np.zeros(self.dimension)\n",
    "        self.spike = np.zeros(self.dimension)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.volt[:] = 0.0\n",
    "        self.spike[:] = 0.0\n",
    "    \n",
    "    def __call__(self, psp_input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            psp_input (ndarray): synaptic inputs \n",
    "        Return:\n",
    "            self.spike: output spikes from the layer\n",
    "                \"\"\"\n",
    "        self.volt = self.vdecay * self.volt * (1. - self.spike) + psp_input\n",
    "        self.spike = (self.volt > self.vth).astype(float)\n",
    "        return self.spike\n",
    "\n",
    "class Connections:\n",
    "    \"\"\" Define connections between spiking neuron layers \"\"\"\n",
    "\n",
    "    def __init__(self, weights, pre_dimension, post_dimension):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (ndarray): connection weights\n",
    "            pre_dimension (int): dimension for pre-synaptic neurons\n",
    "            post_dimension (int): dimension for post-synaptic neurons\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.pre_dimension = pre_dimension\n",
    "        self.post_dimension = post_dimension\n",
    "    \n",
    "    def __call__(self, spike_input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spike_input (ndarray): spikes generated by the pre-synaptic neurons\n",
    "        Return:\n",
    "            psp: postsynaptic layer activations\n",
    "        \"\"\"\n",
    "        psp = np.matmul(self.weights, spike_input)\n",
    "        return psp\n",
    "    \n",
    "    \n",
    "class SNN:\n",
    "    \"\"\" Define a Spiking Neural Network with No Hidden Layer \"\"\"\n",
    "\n",
    "    def __init__(self, input_2_output_weight, \n",
    "                 input_dimension=2, output_dimension=2,\n",
    "                 vdecay=0.5, vth=0.5, snn_timestep=20):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_2_hidden_weight (ndarray): weights for connection between input and hidden layer\n",
    "            hidden_2_output_weight (ndarray): weights for connection between hidden and output layer\n",
    "            input_dimension (int): input dimension\n",
    "            hidden_dimension (int): hidden_dimension\n",
    "            output_dimension (int): output_dimension\n",
    "            vdecay (float): voltage decay of LIF neuron\n",
    "            vth (float): voltage threshold of LIF neuron\n",
    "            snn_timestep (int): number of timesteps for inference\n",
    "        \"\"\"\n",
    "        self.snn_timestep = snn_timestep\n",
    "        self.output_layer = LIFNeurons(output_dimension, vdecay, vth)\n",
    "        self.input_2_output_connection = Connections(input_2_output_weight, input_dimension, output_dimension)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.output_layer.reset_state()\n",
    "    \n",
    "    def __call__(self, spike_encoding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spike_encoding (ndarray): spike encoding of input\n",
    "        Return:\n",
    "            spike outputs of the network\n",
    "        \"\"\"\n",
    "        spike_output = np.zeros(self.output_layer.dimension)\n",
    "        for tt in range(self.snn_timestep):\n",
    "            input_2_output_psp = self.input_2_output_connection(spike_encoding[:, tt])\n",
    "            output_spikes = self.output_layer(input_2_output_psp)\n",
    "            spike_output += output_spikes\n",
    "        return spike_output/self.snn_timestep      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. \n",
    "Next, you need to write a function for network training using hebbian learning rule. The function is defined below. You need to fill in the components so that the network weights are updated in the right manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hebbian(network, train_data, lr=1e-5, epochs=10):\n",
    "    \"\"\" \n",
    "    Function to train a network using Hebbian learning rule\n",
    "        Args:\n",
    "            network (SNN): SNN network object\n",
    "            train_data (list): training data \n",
    "            lr (float): learning rate\n",
    "            epochs (int): number of epochs to train with. Each epoch is defined as one pass over all training samples. \n",
    "        \n",
    "        Write the operations required to compute the weight increment according to the hebbian learning rule. Then increment the network weights. \n",
    "    \"\"\"\n",
    "    \n",
    "    #iterate over the epochs\n",
    "    for ee in range(epochs):\n",
    "        #iterate over all samples in train_data\n",
    "        for data in train_data:\n",
    "            #compute the firing rate for the input\n",
    "\n",
    "            #compute the firing rate for the output\n",
    "\n",
    "            #compute the correlation using the firing rates calculated above\n",
    "\n",
    "            #compute the weight increment\n",
    "\n",
    "            #increment the weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d. \n",
    "In this exercise, you will use your implementations above to train an SNN to learn AND gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a variable for input dimension\n",
    "\n",
    "#Define a variable for output dimension\n",
    "\n",
    "#Define a variable for voltage decay\n",
    "\n",
    "#Define a variable for voltage threshold\n",
    "\n",
    "#Define a variable for snn timesteps\n",
    "\n",
    "#Initialize randomly the weights from input to output. Numpy random rand function might be useful here. \n",
    "\n",
    "#print the initial weights\n",
    "\n",
    "\n",
    "#Initialize an snn using the arguments defined above\n",
    "\n",
    "#Get the training data for AND gate using the function defined in 2a. \n",
    "\n",
    "#Train the network using the function defined in 2c. with the appropriate arguments\n",
    "\n",
    "\n",
    "#Test the trained network and print the network output for all 4 cases. \n",
    "\n",
    "\n",
    "#Print Final Network Weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Limitations of Hebbian Learning rule\n",
    "\n",
    "## 3a. \n",
    "Can you learn the AND gate using 2 neurons in the output layer instead of one? If yes, describe what changes you might need to make to your algorithm in 2b. If not, explain why not, and what consequences it might entail for the use of hebbian learning for complex real-world tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3a.\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. \n",
    "Train the network using hebbian learning for AND gate with the same arguments as defined in 2d. but now multiply the number of epochs by 20. Can your network still learn AND gate correctly? Inspect the initial and final network weights, and compare them against the network weights in 2d. Based on this, explain your observations for the network behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation for 3b. (same as 2d. but with change of one argument)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3b. \n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. \n",
    "Based on your observations and response in 3b., can you explain another limitation of hebbian learning rule w.r.t. weight growth? Can you also suggest a possible remedy for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3c. \n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d. \n",
    "To resolve the issues with hebbian learning, one possibility is Oja's rule. In this exercise, you will implement and train an SNN using Oja's learning rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oja(network, train_data, lr=1e-5, epochs=10):\n",
    "    \"\"\" \n",
    "    Function to train a network using Hebbian learning rule\n",
    "        Args:\n",
    "            network (SNN): SNN network object\n",
    "            train_data (list): training data \n",
    "            lr (float): learning rate\n",
    "            epochs (int): number of epochs to train with. Each epoch is defined as one pass over all training samples. \n",
    "        \n",
    "        Write the operations required to compute the weight increment according to the hebbian learning rule. Then increment the network weights. \n",
    "    \"\"\"\n",
    "    \n",
    "    #iterate over the epochs\n",
    "    for ee in range(epochs):\n",
    "        #iterate over all samples in train_data\n",
    "        for data in train_data:\n",
    "            #compute the firing rate for the input\n",
    "\n",
    "            #compute the firing rate for the output\n",
    "\n",
    "            #compute the weight increment\n",
    "\n",
    "            #increment the weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test your implementation below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a variable for input dimension\n",
    "\n",
    "#Define a variable for output dimension\n",
    "\n",
    "#Define a variable for voltage decay\n",
    "\n",
    "#Define a variable for voltage threshold\n",
    "\n",
    "#Define a variable for snn timesteps\n",
    "\n",
    "#Initialize randomly the weights from input to output. Numpy random rand function might be useful here. \n",
    "\n",
    "#print the initial weights\n",
    "\n",
    "\n",
    "#Initialize an snn using the arguments defined above\n",
    "\n",
    "#Get the training data for AND gate using the function defined in 2a. \n",
    "\n",
    "#Train the network using the function defined in 3d. with the appropriate arguments\n",
    "\n",
    "\n",
    "#Test the trained network and print the network output for all 4 cases. \n",
    "\n",
    "\n",
    "#Print Final Network Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Spike-time dependent plasticity (STDP)\n",
    "\n",
    "## 4a. \n",
    "What is the limitation with hebbian learning that STDP aims to resolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 4a. \n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. \n",
    "Describe the algorithm to train a network using STDP learning rule. You do not need to describe encoding here. Your algorithm should be such that its naturally translatable to a program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 4b. \n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c. \n",
    "In this exercise, you will implement the STDP learning algorithm to train a network. STDP has many different flavors. For this exercise, we will use the learning rule defined in: https://dl.acm.org/doi/pdf/10.1609/aaai.v33i01.330110021. Pay special attention to Equations 2 and 3. \n",
    "\n",
    "Below is the class definition for STDP learning algorithm. Your task is to fill in the components so that the weights are updated in the right manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STDP():\n",
    "    \"\"\"Train a network using STDP learning rule\"\"\"\n",
    "    def __init__(self, network, A_plus, A_minus, tau_plus, tau_minus, lr, snn_timesteps=20, epochs=30, w_min=0, w_max=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            network (SNN): network which needs to be trained\n",
    "            A_plus (float): STDP hyperparameter\n",
    "            A_minus (float): STDP hyperparameter\n",
    "            tau_plus (float): STDP hyperparameter\n",
    "            tau_minus (float): STDP hyperparameter\n",
    "            lr (float): learning rate\n",
    "            snn_timesteps (int): SNN simulation timesteps\n",
    "            epochs (int): number of epochs to train with. Each epoch is defined as one pass over all training samples.  \n",
    "            w_min (float): lower bound for the weights\n",
    "            w_max (float): upper bound for the weights\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "        self.A_plus = A_plus\n",
    "        self.A_minus = A_minus\n",
    "        self.tau_plus = tau_plus\n",
    "        self.tau_minus = tau_minus\n",
    "        self.snn_timesteps = snn_timesteps\n",
    "        self.lr = lr\n",
    "        self.time = np.arange(0, self.snn_timesteps, 1)\n",
    "        self.sliding_window = np.arange(-4, 4, 1) #defines a sliding window for STDP operation. \n",
    "        self.epochs = epochs\n",
    "        self.w_min = w_min\n",
    "        self.w_max = w_max\n",
    "    \n",
    "    def update_weights(self, t, i):\n",
    "        \"\"\"\n",
    "        Function to update the network weights using STDP learning rule\n",
    "        \n",
    "        Args:\n",
    "            t (int): time difference between postsynaptic spike and a presynaptic spike in a sliding window\n",
    "            i(int): index of the presynaptic neuron\n",
    "        \n",
    "        Fill the details of STDP implementation\n",
    "        \"\"\"\n",
    "        #compute delta_w for positive time difference\n",
    "        if t>0:\n",
    "\n",
    "        #compute delta_w for negative time difference\n",
    "        else:\n",
    "\n",
    "            \n",
    "        #update the network weights if weight increment is negative\n",
    "        if delta_w < 0:\n",
    "\n",
    "        #update the network weights if weight increment is positive\n",
    "        elif delta_w > 0:\n",
    "\n",
    "            \n",
    "    def train_step(self, train_data_sample):\n",
    "        \"\"\"\n",
    "        Function to train the network for one training sample using the update function defined above. \n",
    "        \n",
    "        Args:\n",
    "            train_data_sample (list): a sample from the training data\n",
    "            \n",
    "        This function is complete. You do not need to do anything here. \n",
    "        \"\"\"\n",
    "        input = train_data_sample[0]\n",
    "        output = train_data_sample[1]\n",
    "        for t in self.time:\n",
    "            if output[t] == 1:\n",
    "                for i in range(2):\n",
    "                    for t1 in self.sliding_window:\n",
    "                        if (0<= t + t1 < self.snn_timesteps) and (t1!=0) and (input[i][t+t1] == 1):\n",
    "                            self.update_weights(t1, i)\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        \"\"\"\n",
    "        Function to train the network\n",
    "        \n",
    "        Args:\n",
    "            training_data (list): training data\n",
    "        \n",
    "        This function is complete. You do not need to do anything here. \n",
    "        \"\"\"\n",
    "        for ee in range(self.epochs):\n",
    "            for train_data_sample in training_data:\n",
    "                self.train_step(train_data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a variable for input dimension\n",
    "\n",
    "#Define a variable for output dimension\n",
    "\n",
    "#Define a variable for voltage decay\n",
    "\n",
    "#Define a variable for voltage threshold\n",
    "\n",
    "#Define a variable for snn timesteps\n",
    "\n",
    "#Initialize randomly the weights from input to output. Numpy random rand function might be useful here. \n",
    "\n",
    "#Initialize an snn using the arguments defined above\n",
    "\n",
    "#Get the training data for AND gate using the function defined in 2a. \n",
    "\n",
    "#Create an object of STDP class with appropriate arguments\n",
    "\n",
    "#Train the network using STDP\n",
    "\n",
    "#Test the trained network and print the network output for all 4 cases. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: OR Gate\n",
    "Can you train the network with the same architecture in Q2-4 for learning the OR gate. You will need to create another function called genORTrainData. Then create an SNN and train it using STDP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your implementation of genORTrainData here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the network for OR gate here using the implementation from 4c. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: XOR Gate\n",
    "In this question, we will construct and train a multi-layer SNN with a single hidden layer to solve the XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. \n",
    "Explain why a hidden layer is required for the XOR problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6a.\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b. \n",
    "You will need to create another function called genXORTrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your implementation of genXORTrainData here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6c. \n",
    "You will need to create a 2-layer SNN using the LIFNeurons and Connections classes defined above. In addition to neurons defined at each layer, assume each non-output layer also contains a **tonic bias neuron** (neuron with **sustained** activity) that represents the background activity observed in each layer of a brain region defined by the SNN. A schematic for this is attached below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SNN_with_bias.png](SNN_with_bias.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN2Layer:\n",
    "    \"\"\"\n",
    "    Two-layer SNN using provided LIFNeurons and Connections.\n",
    "    Forward returns mean output spikes (rate) over the trial.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, W_in_h, W_h_out,\n",
    "                 input_dimension=2, hidden_dimension=24, output_dimension=1,\n",
    "                 vdecay=0.5, vth=0.8, snn_timestep=50,\n",
    "                 hidden_bias=0.08, output_bias=0.05):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            W_in_h   (ndarray): shape (hidden_dimension, input_dimension), init weights\n",
    "            W_h_out  (ndarray): shape (output_dimension, hidden_dimension), init weights\n",
    "            vdecay   (float): membrane decay for LIF layers\n",
    "            vth      (float): spike threshold for LIF layers\n",
    "            snn_timestep (int): steps per trial\n",
    "            hidden_bias (float): small tonic bias added to hidden PSP each step\n",
    "            output_bias (float): small tonic bias added to output PSP each step\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def forward_rates(self, spike_encoding):\n",
    "        \"\"\"\n",
    "        Run one trial and return:\n",
    "            h_rate: mean hidden spikes per time step, shape (H,)\n",
    "            o_rate: mean output spikes per time step, shape (1,)\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def __call__(self, spike_encoding):\n",
    "        \"\"\"Return mean output spikes (rate) over the trial, shape (1,).\"\"\"\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6d. \n",
    "To train a network to solve the XOR problem, we will need to modify the Hebbian Learning Rule to use a biologically-motivated **3-factor modified Hebbian rule** that extends the rule with **supervision**. \n",
    "\n",
    "Core idea behind 3-factor rule:\n",
    "* Let o_rate be the output neuron’s mean firing rate on a sample.\n",
    "* Let h_rate be the hidden layer’s mean firing rates vector.\n",
    "* Let in_rate be the input rates vector.\n",
    "* Let y ∈ {0,1} be the target label for that sample (decoded from the label spikes).\n",
    "* Let e = y - o_rate, represent the scalar error\n",
    "  \n",
    "**Update with centered activities to remove baseline bias**:\n",
    "*    Keep exponential moving averages (EMAs) of hidden and input rates, h̄ and ī.\n",
    "*    Center: h_c = h_rate - h̄, in_c = in_rate - ī.\n",
    "**Weight updates (per sample)**:\n",
    "*    Output weights: ΔW_h_out = η_out * e * h_c (Hebb with error gate)\n",
    "*    Hidden weights: ΔW_in_h = η_in * e * (h_c ⊗ in_c) (outer product)\n",
    "**Add tiny Oja-like decay terms to prevent runaway growth**:\n",
    "*    W_h_out ← W_h_out − λ_out * (o_rate²) * W_h_out\n",
    "*    W_in_h ← W_in_h − λ_in * (h_rate²) ⊙ W_in_h (row-wise)\n",
    "**Clip weights to [w_min, w_max] after each sample**\n",
    "\n",
    "This is “Hebb + (global) error” (a 3-factor rule) with centering and mild normalization.\n",
    "\n",
    "**Note**: To avoid overfitting a single draw of Poisson spikes and to make the network learn rate mappings, regenerate the four XOR patterns every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedHebbXOR:\n",
    "    \"\"\"\n",
    "    3-factor modified Hebbian learning:\n",
    "        e = y - o_rate\n",
    "        ΔW_h_out = η_out * e * h_c\n",
    "        ΔW_in_h  = η_in  * e * (h_c ⊗ in_c)\n",
    "    with EMA-centered rates (h̄, ī), tiny Oja-like decay, and clipping.\n",
    "    Generates fresh spike trains each epoch to learn rates.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network: SNN2Layer,\n",
    "                 lr_in=0.02, lr_out=0.05, epochs=600,\n",
    "                 w_min=-2.0, w_max=2.0,\n",
    "                 l2_in=1e-4, l2_out=1e-4,\n",
    "                 decode_thresh=0.35, ema=0.97,\n",
    "                 snn_timesteps=50):\n",
    "        ...\n",
    "\n",
    "    def _epoch_data(self):\n",
    "        \"\"\"\n",
    "        Return a fresh XOR training set each epoch:\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        For each epoch: get fresh XOR data and update model weights\n",
    "        \"\"\"\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6e \n",
    "Now test your implementation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Build, train XOR from RANDOM init, test\n",
    "# ----------------------------\n",
    "# Define hyperparameters below        \n",
    "\n",
    "# Randomly initalize the model weights\n",
    "W_in_h  = np.random.uniform(-0.8, 0.8, size=(hid_dim, in_dim)) #You must define hid_dim, in_dim, and out_dim\n",
    "W_h_out = np.random.uniform(-0.8, 0.8, size=(out_dim, hid_dim))\n",
    "\n",
    "print(\"Initial W_in_h (excerpt):\\n\", W_in_h[:3])\n",
    "print(\"Initial W_h_out (excerpt):\\n\", W_h_out[:, :6])\n",
    "\n",
    "# Define 2-layer SNN for XOR problem\n",
    "snn_xor = None\n",
    "\n",
    "#Train the SNN with ModifiedHebbXOR\n",
    "\n",
    "# Evaluate results on one fresh draw of the four truth-table rows using genXORTrainData (print both the input data and the predicted values)\n",
    "\n",
    "\n",
    "print(\"\\nFinal W_in_h (excerpt):\\n\", snn_xor.input_2_hidden_connection.weights[:3]) #You must define the class variables in your SNN2Layer class\n",
    "print(\"Final W_h_out (excerpt):\\n\", snn_xor.hidden_2_output_connection.weights[:, :6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 — Geometric PCA (closed form)\n",
    "\n",
    "In this question we switch from *spikes over time* to a more geometric view of the\n",
    "same data. Each trial of the AND gate produces a 2-D **rate vector** $\\mathbf{x}\\in\\mathbb{R}^2$ (one rate for each input channel). On this small\n",
    "dataset we can:\n",
    "\n",
    "1. Visualize the **geometry** of the four AND patterns as clusters in 2-D.\n",
    "2. Use **Principal Component Analysis (PCA)** to find the directions of maximum\n",
    "   variance.\n",
    "3. Show how a simple **Hebbian learning rule with normalization** (Oja’s rule)\n",
    "   performs online PCA.\n",
    "4. Use the learned principal components as **features** for a simple AND\n",
    "   classifier.\n",
    "5. Extend to two PCs using **Sanger’s / GHA rule**, and relate reconstruction\n",
    "   error to the **eigenvalues** of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7a. Dataset: many AND samples as **rate vectors**\n",
    "We convert each spike sample (2×T) to a rate vector $x\\in\\mathbb{R}^2$ by averaging across time, and derive the class label (AND of the two bits).\n",
    "\n",
    "In earlier questions you generated spike trains for a 2-input AND gate:\n",
    "\n",
    "- Each trial gives a spike matrix of shape \\($2 \\times T$\\):  \n",
    "  one row for input A, one row for input B, across \\(T\\) time steps.\n",
    "- We convert this to a **rate vector** by averaging over time:\n",
    "  \n",
    "  $\\mathbf{x} = \\frac{1}{T} \\sum_{t=1}^{T} \\mathbf{s}(t) \\in \\mathbb{R}^2$,\n",
    "  \n",
    "  so \\(\\mathbf{x} = (r_A, r_B)\\) is the firing rate of each input neuron.\n",
    "- The **label** for that trial is the logical AND of the underlying bits\n",
    "  (0 or 1).\n",
    "\n",
    "Geometric picture:\n",
    "\n",
    "- The four AND patterns \\((0,0), (1,0), (0,1), (1,1)\\) become four **clusters**\n",
    "  in the 2-D rate plane.\n",
    "- Noise in the spike encoding spreads each pattern into a little **blob**.\n",
    "- PCA on these rate vectors will discover the main directions along which these\n",
    "  blobs vary the most (e.g., roughly along the \\([1,1]\\) diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def sample_AND_dataset(N=2000, T=20):\n",
    "    X_rates, y = [], []\n",
    "    for _ in range(N):\n",
    "        cases = genANDTrainData(T)\n",
    "        idx   = rng.integers(0, 4)\n",
    "        x_spk, y_spk = cases[idx]\n",
    "        x_rate = x_spk.mean(axis=1)\n",
    "        bits = [(0,0),(1,0),(0,1),(1,1)][idx]\n",
    "        y_lbl = int(bits[0] & bits[1])\n",
    "        X_rates.append(x_rate)\n",
    "        y.append(y_lbl)\n",
    "    X = np.vstack(X_rates).astype(float)\n",
    "    y = np.asarray(y, int)\n",
    "    return X, y\n",
    "\n",
    "T = 20\n",
    "X, y = sample_AND_dataset(N=4000, T=T)\n",
    "mu = X.mean(axis=0)\n",
    "Xc = X - mu\n",
    "print(\"X shape:\", X.shape, \"  mean:\", mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute empirical covariance matrix of the centered data.\n",
    "# Note: using N (Xc.shape[0]) in the denominator gives the population covariance estimate.\n",
    "\n",
    "# eigvals/eigvecs from np.linalg.eigh are returned in ascending order for symmetric matrices.\n",
    "# ascending order\n",
    "\n",
    "# Reverse to get descending order: lam[0] is the largest eigenvalue.\n",
    "\n",
    "# Reorder eigenvectors so columns correspond to eigenvectors for lam[0], lam[1], ...\n",
    "# columns v1, v2\n",
    "\n",
    "# Extract the first and second principal component unit vectors.\n",
    "\n",
    "# Comments for students:\n",
    "# - lam contains the variances along each principal direction (eigenvalues).\n",
    "# - v1 is the direction of maximum variance (first principal component).\n",
    "# - Scaling arrows by sqrt(lam) gives a visual sense of standard deviation along each PC.\n",
    "print(\"λ:\", lam)\n",
    "\n",
    "plt.figure(figsize=(4.5,4.2))\n",
    "plt.scatter(Xc[:,0], Xc[:,1], s=8, alpha=0.15, label='centered')\n",
    "scale = 3*np.sqrt(lam[0])\n",
    "plt.arrow(0,0, *(scale*v1), color='C1', width=0.002, length_includes_head=True, label='v1')\n",
    "plt.arrow(0,0, *(2*np.sqrt(lam[1])*v2), color='C2', width=0.002, length_includes_head=True, label='v2')\n",
    "plt.axhline(0, color='k', lw=0.5); plt.axvline(0, color='k', lw=0.5)\n",
    "plt.legend(); plt.title('Centered AND rates + PCA axes'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 7b. — **Oja’s rule** (online PCA, single unit)\n",
    "\n",
    "PCA in closed form comes from the eigenvectors of the covariance matrix\n",
    "\\($\\mathbf{C}$\\) of the data. The **first principal component (PC)** is the unit\n",
    "vector \\($\\mathbf{w}_1$\\) that maximizes the variance of the projection\n",
    "\\($\\mathbf{w}_1^\\top \\mathbf{x}$\\).\n",
    "\n",
    "Oja’s rule gives us an **online**, neuron-like way to learn this direction:\n",
    "\n",
    "- Neuron output: \\($y = \\mathbf{w}^\\top \\mathbf{x}$\\).\n",
    "- Weight update:\n",
    "  \\[\n",
    "  $\\Delta \\mathbf{w} = \\eta\\, y \\bigl(\\mathbf{x} - y\\,\\mathbf{w}\\bigr)$,\n",
    "  \\]\n",
    "  with small learning rate \\($\\eta$\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oja_fit(Xc, lr=5e-3, epochs=10, w0=None, normalize_each_epoch=True, rng=rng):\n",
    "    \"\"\"\n",
    "    Online PCA with Oja's rule (single principal component).\n",
    "\n",
    "    Args:\n",
    "        Xc : (N, D) data matrix, already mean-centered (zero-mean per feature)\n",
    "        lr : learning rate η for Oja's rule\n",
    "        epochs : number of passes over the dataset\n",
    "        w0 : optional initial weight vector (D,). If None, random init.\n",
    "        normalize_each_epoch : if True, L2-normalize w at the end of each epoch\n",
    "        rng : NumPy random generator (for init and shuffling)\n",
    "\n",
    "    Returns:\n",
    "        w         : learned principal component (D,)\n",
    "        cos_hist  : cosine similarity between w and true top eigenvector per epoch\n",
    "        var_hist  : variance explained along w per epoch (mean squared projection)\n",
    "    \"\"\"\n",
    "\n",
    "    # Dimensionality of each sample\n",
    "    D = Xc.shape[1]\n",
    "\n",
    "    # Initialize weight vector w (our 1D \"neuron\") – random or from w0\n",
    "\n",
    "    # Normalize initial w to unit length (helps stability & comparability)\n",
    "\n",
    "    # For tracking learning progress\n",
    "    # cosine similarity to true top PC\n",
    "    # variance captured along w\n",
    "\n",
    "    # Compute the true top eigenvector v1 for comparison (offline PCA)\n",
    "    # Covariance (up to a constant factor) is (X^T X)/N\n",
    "\n",
    "    # eigh returns eigenvalues/eigenvectors; columns of evecs = eigenvectors\n",
    "    # top eigenvector (largest eigenvalue)\n",
    "\n",
    "    # --------- Oja's online learning loop ---------\n",
    "    for ep in range(epochs):\n",
    "        # Iterate over samples in a random order each epoch\n",
    "            # x: (D,) one sample\n",
    "            # Neuron output (projection on w)\n",
    "\n",
    "            # Oja's rule update:\n",
    "            # Δw = η [ y x  - y^2 w ]\n",
    "            # Hebbian term:     y x      (push w towards high-variance directions)\n",
    "            # Normalization:   -y^2 w    (prevents unbounded growth)\n",
    "\n",
    "        # Optional normalization of w after each epoch (keeps ||w|| ≈ 1)\n",
    "        \n",
    "\n",
    "    # ---- Diagnostics: how close are we to the true PC? ----\n",
    "    # Cosine similarity between learned w and true v1\n",
    "\n",
    "    # Variance explained along w: mean of (projection)^2\n",
    "    # proj = Xc w  → (N,)\n",
    "    # var = E[proj^2]\n",
    "    \n",
    "    return w, np.array(cos_hist), np.array(var_hist)\n",
    "\n",
    "w_oja, cos_h, var_h = oja_fit(Xc, lr=5e-3, epochs=20)\n",
    "print(\"Final w:\", w_oja)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,3.2))\n",
    "ax[0].plot(cos_h); ax[0].set_ylabel('cos(w, v1)'); ax[0].set_xlabel('epoch'); ax[0].grid(True)\n",
    "ax[1].plot(var_h); ax[1].set_ylabel('E[y^2]');    ax[1].set_xlabel('epoch'); ax[1].grid(True)\n",
    "fig.suptitle('Oja convergence'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 7c. — Use the learned PC as a **feature** for AND\n",
    "\n",
    "Once Oja’s rule has converged, we have an estimate of the first PC\n",
    "\\($\\hat{\\mathbf{w}}_1$\\). We can turn any input \\($\\mathbf{x}$\\) into a **1-D\n",
    "feature**:\n",
    "\n",
    "\\[\n",
    "$z = \\hat{\\mathbf{w}}_1^\\top \\mathbf{x}.$\n",
    "\\]\n",
    "\n",
    "This scalar \\(z\\):\n",
    "\n",
    "- Captures most of the variance in the 2-D rate space.\n",
    "- Tends to send the \\((1,1)\\) (AND = 1) cluster to a different region of the\n",
    "  1-D axis than the other three patterns.\n",
    "\n",
    "A very simple classifier is then:\n",
    "\n",
    "- “Predict AND = 1 if \\(z\\) is above some threshold, else 0.”\n",
    "\n",
    "In other words, Oja’s rule has discovered a **useful projection direction** that\n",
    "acts as a hand-crafted feature for the AND decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Xc @ w_oja  # scalar feature\n",
    "\n",
    "def thresh_from_data(z, y):\n",
    "    \"\"\"Find the best classification threshold by scanning percentiles of z.\n",
    "    \n",
    "    Args:\n",
    "        z: scalar feature values from PCA projection\n",
    "        y: true labels (0 or 1)\n",
    "        \n",
    "    Returns:\n",
    "        best_t: threshold giving highest accuracy\n",
    "        best_acc: accuracy achieved at best threshold\n",
    "    \"\"\"\n",
    "    # Try n (quantity) thresholds at percentiles from 5% to 95%\n",
    "    \n",
    "    # For each percentile, compute threshold and test accuracy\n",
    "    \n",
    "    return best_t, best_acc\n",
    "\n",
    "# Find best threshold and corresponding accuracy\n",
    "t_star, acc_star = thresh_from_data(z, y)\n",
    "\n",
    "# Make predictions using best threshold\n",
    "pred = (z > t_star).astype(int)\n",
    "\n",
    "# Build 2x2 confusion matrix\n",
    "# Rows = true labels, Cols = predicted labels\n",
    "cm = np.zeros((2,2), int)\n",
    "for yi, pi in zip(y, pred):\n",
    "    cm[yi, pi] += 1  # Count (true,pred) occurrences\n",
    "\n",
    "print(\"Chosen threshold:\", round(float(t_star),4), \"  accuracy:\", round(float(acc_star),4))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "plt.figure(figsize=(5,3.2))\n",
    "plt.hist(z[y==0], bins=30, alpha=0.6, label='y=0')\n",
    "plt.hist(z[y==1], bins=30, alpha=0.6, label='y=1')\n",
    "plt.axvline(t_star, color='k', linestyle='--', label='threshold')\n",
    "plt.legend(); plt.xlabel('z = w^T (x-μ)'); plt.ylabel('count'); plt.title('Single-PC feature for AND');\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 7d. — Two PCs with **Sanger/GHA**\n",
    "\n",
    "Oja’s rule only gives us **one** PC. To learn **multiple** PCs in one pass, we\n",
    "use **Sanger’s rule** (also called the **Generalized Hebbian Algorithm, GHA**).\n",
    "\n",
    "- We now have a weight matrix\n",
    "  \\($\\mathbf{W} = [\\mathbf{w}_1,\\dots,\\mathbf{w}_k] \\in \\mathbb{R}^{d \\times k}$\\).\n",
    "- For each input \\($\\mathbf{x}$\\), neuron outputs are\n",
    "  \\($\\mathbf{y} = \\mathbf{W}^\\top \\mathbf{x}$\\), so \\($y_i = \\mathbf{w}_i^\\top \\mathbf{x}$\\).\n",
    "- The update for column \\(i\\) is:\n",
    "  \\[\n",
    "  $\\Delta \\mathbf{w}_i = \\eta\\, y_i \\left(\n",
    "      \\mathbf{x} - \\sum_{j=1}^{i} y_j\\,\\mathbf{w}_j\n",
    "  \\right)$.\n",
    "  \\]\n",
    "\n",
    "Key ideas:\n",
    "\n",
    "- Each neuron does a Hebbian-plus-normalization update **after removing** the\n",
    "  contribution of all earlier PCs \\($\\mathbf{w}_1,\\dots,\\mathbf{w}_{i-1}$\\).\n",
    "- The learned \\($\\mathbf{w}_i$\\) become approximately **orthonormal** and\n",
    "  converge to the eigenvectors of the covariance matrix in order:\n",
    "  \\($\\mathbf{w}_1$ \\to\\) first PC, \\($\\mathbf{w}_2$ \\to\\) second PC, etc.\n",
    "\n",
    "For the AND rate dataset in 2-D:\n",
    "\n",
    "- With \\(k=2\\), Sanger’s rule should recover both principal directions.\n",
    "- You can visualize these vectors on top of the scatter plot of \\($\\mathbf{x}$\\)\n",
    "  to see how they align with the four AND clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanger_fit(Xc, K=2, lr=5e-3, epochs=20, rng=rng):\n",
    "    \"\"\"\n",
    "    Implements Sanger's rule (GHA) for finding K principal components.\n",
    "    \n",
    "    Args:\n",
    "        Xc: Mean-centered data matrix of shape (N, D)\n",
    "        K: Number of principal components to learn (default=2)\n",
    "        lr: Learning rate for weight updates (default=5e-3)\n",
    "        epochs: Number of passes through the dataset (default=20)\n",
    "        rng: Random number generator for initialization/shuffling\n",
    "    \n",
    "    Returns:\n",
    "        W: Weight matrix of shape (K,D) where rows approximate principal components\n",
    "    \"\"\"\n",
    "    # Initialize random weights for K neurons, each taking D inputs\n",
    "    D = Xc.shape[1]  # Input dimension\n",
    "    \n",
    "    # Normalize each weight vector to unit length for stability\n",
    "\n",
    "\n",
    "    # Training loop over epochs\n",
    "\n",
    "        # Process samples in random order each epoch\n",
    "\n",
    "            # Compute neuron outputs y = Wx\n",
    "                        \n",
    "            # Update each neuron's weights in order (k=1,2,...,K)\n",
    "            \n",
    "                # Compute projection onto current and previous neurons\n",
    "                \n",
    "                    \n",
    "                # Sanger's update: Hebbian term minus projections\n",
    "                \n",
    "                \n",
    "        # Re-normalize weights after each epoch\n",
    "        \n",
    "    \n",
    "    return W\n",
    "\n",
    "W2 = sanger_fit(Xc, K=2, lr=5e-3, epochs=30)\n",
    "print(\"W2 (rows):\\n\", W2)\n",
    "\n",
    "C = (Xc.T @ Xc) / Xc.shape[0]\n",
    "eigvals, eigvecs = np.linalg.eigh(C)\n",
    "V = eigvecs[:, ::-1]\n",
    "cos1 = abs(float(W2[0] @ V[:,0])); cos2 = abs(float(W2[1] @ V[:,1]))\n",
    "orth = float(W2[0] @ W2[1])\n",
    "print(f\"cos(w1,v1)={cos1:.3f},  cos(w2,v2)={cos2:.3f},  w1·w2={orth:.3f}\")\n",
    "\n",
    "Y2 = Xc @ W2.T\n",
    "plt.figure(figsize=(4.5,4.2))\n",
    "plt.scatter(Y2[:,0], Y2[:,1], c=y, cmap='coolwarm', s=10, alpha=0.6)\n",
    "plt.axhline(0, color='k', lw=0.5); plt.axvline(0, color='k', lw=0.5)\n",
    "plt.xlabel('y1'); plt.ylabel('y2'); plt.title('Sanger outputs (2 PCs)'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 7e — Reconstruction error vs #PCs and eigenvalues\n",
    "\n",
    "PCA is often described in terms of **reconstruction**:\n",
    "\n",
    "- Let the covariance matrix of the data be \\($\\mathbf{C}$\\) with eigenvalues\n",
    "  \\($\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_d$\\) and eigenvectors\n",
    "  (PCs) \\($\\mathbf{w}_1,\\dots,\\mathbf{w}_d$\\).\n",
    "- The **total variance** of the data is\n",
    "  \\($\\sum_{i=1}^{d} \\lambda_i$\\).\n",
    "- If we keep only the first \\(k\\) PCs, the variance captured is\n",
    "  \\($\\sum_{i=1}^{k} \\lambda_i$\\).\n",
    "- The expected **reconstruction mean-squared error** when projecting onto the\n",
    "  first \\(k\\) PCs is:\n",
    "  \\[\n",
    "  $E_{\\text{recon}}(k) = \\sum_{i=k+1}^{d} \\lambda_i$,\n",
    "  \\]\n",
    "  i.e. the sum of the **discarded** eigenvalues.\n",
    "\n",
    "For this 2-D AND dataset:\n",
    "\n",
    "- With 1 PC, the reconstruction error is just the second eigenvalue \\($\\lambda_2$\\).\n",
    "- With 2 PCs, the reconstruction error is essentially 0 (you’re using the full\n",
    "  2-D space again).\n",
    "- Plotting reconstruction error vs number of PCs, alongside the eigenvalues\n",
    "  themselves, makes the link clear:\n",
    "  - **Large eigenvalues** correspond to important directions in the data.\n",
    "  - **Discarded eigenvalues** directly measure how much information you lose\n",
    "    when using only a subset of PCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a,b): return float(np.mean((a-b)**2))\n",
    "C = (Xc.T @ Xc) / Xc.shape[0]\n",
    "eigvals, eigvecs = np.linalg.eigh(C)\n",
    "lam = eigvals[::-1]\n",
    "\n",
    "# K=1 using Oja (unit norm)\n",
    "w1 = (W2[0] / (np.linalg.norm(W2[0])+1e-12))\n",
    "Xh1 = np.outer(Xc @ w1, w1)\n",
    "mse1 = mse(Xc, Xh1)\n",
    "\n",
    "# K=2 using Sanger (orthonormalize rows with QR)\n",
    "Q,_ = np.linalg.qr(W2.T)\n",
    "W_orth = Q.T\n",
    "Xh2 = (Xc @ W_orth.T) @ W_orth\n",
    "mse2 = mse(Xc, Xh2)\n",
    "total_var = float(np.trace(C))\n",
    "print(f\"MSE K=1: {mse1:.5f}  (drop ≈ λ2={lam[1]:.5f})\")\n",
    "print(f\"MSE K=2: {mse2:.5f}  (drop ≈ 0; keeps λ1+λ2={lam.sum():.5f}≈total var {total_var:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### What to report (short write‑ups)\n",
    "- Eigenvalues and a sentence on why $v_1\\approx [1,1]/\\sqrt{2}$ in balanced AND.\n",
    "- Oja curves: `cos(w,v1)` rising to ~1 and `E[y^2]` → $\\lambda_1$.\n",
    "- Histograms of the scalar feature `z` with chosen threshold + confusion matrix.\n",
    "- Sanger alignment (cosines), near‑orthogonality, and 2‑D scatter.\n",
    "- MSE vs K and relation to eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7e Answer\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8\n",
    "## 8a. Implement Sejnowski’s Learning Rule\n",
    "\n",
    "In 1977, Neuroscientist Dr. Terry Sejnowski proposed a form of synaptic modification similar to Hebb’s rule, but with a nonlinear dependence on the postsynaptic firing rate y: $Δw_i=ηy(y−θ)x_i$ where $x_i$ is the presynaptic firing rate, $y$ is the postsynaptic firing rate, $θ$ is the postsynaptic activity threshold, and $η$ is the learning rate. When $y>θ$, weights potentiate (LTP); when  $y<θ$, weights depress (LTD). This introduces a self-stabilizing balance around θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sejnowski_rule(network, train_data, lr=0.01, theta=0.4, epochs=10):\n",
    "    \"\"\"\n",
    "    Function to train a network using Sejnowski's learning rule\n",
    "        Args:\n",
    "            network (SNN): SNN network object\n",
    "            train_data (list): training data \n",
    "            lr (float): learning rate\n",
    "            theta: postsynaptic activity threshold\n",
    "            epochs (int): number of epochs to train with. Each epoch is defined as one pass over all training samples.\n",
    "        \n",
    "        Write the operations required to compute the weight increment according to Sejnowski's learning rule. Then increment the network weights. \n",
    "    \"\"\"\n",
    "    #iterate over the epochs\n",
    "    for ee in range(epochs):\n",
    "        #iterate over all samples in train_data\n",
    "        for x_spikes, _y_spikes in train_data:\n",
    "            # presynaptic (input) rates across time\n",
    "\n",
    "            # postsynaptic (network) mean spike (scalar in [0,1])\n",
    "\n",
    "            # compute weight increment\n",
    "            \n",
    "            #increment the weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b. Implement the BCM (Bienenstock–Cooper–Munro) Rule \n",
    "\n",
    "The BCM rule (Bienenstock et al., 1982) adds a sliding modification threshold $θ_M$ that depends on the recent average postsynaptic activity: $Δw_i = ηy(y−θ_M)x_i$, and $\\frac{dθ_M}{dt} = α(y^2−θ_M)$. When $y>θ_M$, weights potentiate (LTP); $y<θ_M$, weights depress (LTD). $θ_M$ evolves over time to balance potentiation/depression by providing a metaplastic mechanism that keeps the neuron’s output firing rate within a stable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcm_rule(network, train_data, lr=0.01, alpha=0.05, theta_init=0.3, epochs=10):\n",
    "    \"\"\"\n",
    "    Function to train a network using the BCM learning rule\n",
    "        Args:\n",
    "            network (SNN): SNN network object\n",
    "            train_data (list): training data \n",
    "            lr (float): learning rate constant weight update\n",
    "            alpha: learning rate constant for theta update\n",
    "            theta_init: initial value for a sliding (adaptive) postsynaptic modification threshold\n",
    "            epochs (int): number of epochs to train with. Each epoch is defined as one pass over all training samples.\n",
    "        \n",
    "        Write the operations required to compute the weight increment according to the BCM learning rule. Then increment the network weights. \n",
    "    \"\"\"\n",
    "    theta_M = float(theta_init)\n",
    "    #iterate over the epochs\n",
    "    for ee in range(epochs):\n",
    "        #iterate over all samples in train_data\n",
    "        for x_spikes, _y_spikes in train_data:\n",
    "            # compute values for weight increment\n",
    "\n",
    "            # compute weight increment\n",
    "            \n",
    "            # increment the weight\n",
    "\n",
    "            # sliding threshold update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8c. Compare Learning Rules Experimentally on Changing Inputs\n",
    "\n",
    "You’ll implement and compare five learning rules in a tiny SNN (2 inputs → 1 output): Hebbian (plain), Oja, Sejnowski, BCM, and STDP.\n",
    "\n",
    "You will run two experiments:\n",
    "\n",
    "**Task A** — Non-stationary Feature Tracking: Generate spike streams where the input covariance changes halfway through training:\n",
    "* Phase 1 (epochs 1…E/2): variance aligned with vector v₁ = [1, 0.2]ᵀ\n",
    "* Phase 2 (epochs E/2+1…E): variance aligned with v₂ = [0.2, 1]ᵀ\n",
    "\n",
    "Train your single-output neuron with each rule (starting from the **same** random weights). At each epoch, present new random spike trains (rate-coded). After each epoch, compute the angle between the synaptic weight vector w and the current empirical first principal component (PC₁) of the input stream.\n",
    "\n",
    "What to look for:\n",
    "* Oja: angles drop toward ~0° in Phase 1, then re-align toward v₂ in Phase 2.\n",
    "* Hebb: weight norm explodes; angle is unreliable.\n",
    "* Sejnowski (fixed θ): can stabilize near θ but may fail to track the principal component switch unless θ is tuned.\n",
    "* BCM: sliding θ homeostatically keeps firing near a target; tracks the principal component switch but can lag the switch.\n",
    "* STDP: not a rate/principal component learner; angles will be noisy/uninformative.\n",
    "\n",
    "**Task B** — Temporal Causality (pre→post timing)\n",
    "* Make x₁ spikes tend to precede x₂ by Δt in Phase 1; reverse the order in Phase 2.\n",
    "\n",
    "Train the same neuron with STDP and compare to rate-rules just as you do for Task A. Report the sign and magnitude of w₁ vs w₂ at the end of each phase.\n",
    "\n",
    "What to look for:\n",
    "* STDP: w₁ > w₂ after Phase 1 (x₁ leads), then flips to w₂ > w₁ after Phase 2.\n",
    "* Hebb/Oja/Sejnowski/BCM: largely fail to flip based on timing alone.\n",
    "\n",
    "**Note**: Test your implementation below and explain the observed result (make sure to compare across learning rules for both tasks). **Interpret** the output of the results, make sure to **explain** what the magnitude of the weight vector and the angle between the weight vector and first principal component tell us and **what they mean**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers: angles, PCs, generators\n",
    "# DO NOT CHANGE ANYTHING HERE\n",
    "# =========================\n",
    "def _angle_deg(u, v, eps=1e-9):\n",
    "    u = u.ravel().astype(float); v = v.ravel().astype(float)\n",
    "    nu = np.linalg.norm(u) + eps; nv = np.linalg.norm(v) + eps\n",
    "    cos = np.clip(np.dot(u, v) / (nu * nv), -1.0, 1.0)\n",
    "    return float(np.degrees(np.arccos(cos)))\n",
    "\n",
    "def _pc1_from_spikes(X):\n",
    "    Xc = X - X.mean(axis=1, keepdims=True)\n",
    "    C = Xc @ Xc.T / max(1, X.shape[1] - 1)\n",
    "    vals, vecs = np.linalg.eigh(C)\n",
    "    v = vecs[:, np.argmax(vals)]\n",
    "    if v[0] < 0: v = -v\n",
    "    return v\n",
    "\n",
    "def gen_phase_spikes_cov(T, v_dir, lo=0.02, hi=0.25, mix=0.15, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    v = np.asarray(v_dir, dtype=float)\n",
    "    v = v / (np.linalg.norm(v) + 1e-9)\n",
    "    u = np.array([-v[1], v[0]])\n",
    "    z_major = rng.random(T) < hi\n",
    "    z_minor = rng.random(T) < lo\n",
    "    z_iso   = rng.random((2, T)) < mix\n",
    "    x = (np.outer(v, z_major.astype(float)) +\n",
    "         np.outer(u, z_minor.astype(float))) > 0.5\n",
    "    X = x.astype(int) | z_iso.astype(int)\n",
    "    return X\n",
    "\n",
    "def gen_phase_spikes_temporal(T, lead=0, lag=2, base=0.05, burst=0.35, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    x1 = (rng.random(T) < base).astype(int)\n",
    "    x2 = (rng.random(T) < base).astype(int)\n",
    "    if lead == 1:\n",
    "        for t in range(T - lag):\n",
    "            if x1[t] == 1 and rng.random() < burst:\n",
    "                x2[t + lag] = 1\n",
    "    elif lead == 2:\n",
    "        for t in range(T - lag):\n",
    "            if x2[t] == 1 and rng.random() < burst:\n",
    "                x1[t + lag] = 1\n",
    "    return np.stack([x1, x2])\n",
    "\n",
    "# =========================\n",
    "# One-step adapters that use your learning rule functions defined above\n",
    "# DO NOT CHANGE ANYTHING HERE\n",
    "# =========================\n",
    "def sejnowski_step(network, X, lr=0.01, theta=0.4, repeats=1):\n",
    "    train_data = [(X, None)] * repeats\n",
    "    sejnowski_rule(network, train_data, lr=lr, theta=theta, epochs=1)\n",
    "\n",
    "def bcm_step(network, X, theta_M, lr=0.01, alpha=0.05, repeats=1):\n",
    "    train_data = [(X, None)] * repeats\n",
    "    theta_M = bcm_rule(network, train_data, lr=lr, alpha=alpha, theta_init=theta_M, epochs=1)\n",
    "    return theta_M\n",
    "\n",
    "def hebbian_step(network, X, y_teacher, lr=1e-5, repeats=1):\n",
    "    \"\"\"Call your hebbian() once per minibatch (optionally repeated).\"\"\"\n",
    "    train_data = [(X, y_teacher)] * repeats\n",
    "    hebbian(network, train_data, lr=lr, epochs=1)\n",
    "\n",
    "def oja_step(network, X, y_teacher, lr=1e-5, repeats=1):\n",
    "    \"\"\"Call your oja() once per minibatch (optionally repeated).\"\"\"\n",
    "    train_data = [(X, y_teacher)] * repeats\n",
    "    oja(network, train_data, lr=lr, epochs=1)\n",
    "\n",
    "# =========================\n",
    "# Task A: Non-stationary feature tracking\n",
    "# =========================\n",
    "def taskA_compare_rules(epochs=80, T=90, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    W0 = rng.uniform(-1.2, 1.2, size=(1, 2)) #Initialize weights\n",
    "\n",
    "    nets = { # Initialize Networks\n",
    "        'Hebb':       SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'Oja':        SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'Sejnowski':  SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'BCM':        SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'STDP':       SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "    }\n",
    "\n",
    "    # Define necessary objects and hyperparameters for each SNN\n",
    "    \n",
    "    # Task-parameters; DO NOT CHANGE\n",
    "    v1 = np.array([1.0, 0.2]); v2 = np.array([0.2, 1.0])\n",
    "    phase_switch = epochs // 2\n",
    "\n",
    "    print(\"\\n=== Task A: Non-stationary feature tracking ===\")\n",
    "    for e in range(epochs):\n",
    "        # Input data computation for task A; DO NOT CHANGE\n",
    "        v = v1 if e < phase_switch else v2\n",
    "        X = gen_phase_spikes_cov(T, v, lo=0.08, hi=0.50, mix=0.25, rng=rng)\n",
    "        pc1 = _pc1_from_spikes(X)\n",
    "        y_teacher = (X[0] | X[1]).astype(int) # Teacher for Hebb/Oja/STDP in Task A: OR of inputs\n",
    "\n",
    "        for _ in range(3):\n",
    "            # Todo: train your SNNs using step functions above\n",
    "\n",
    "        # Print learned weights at key points during learning\n",
    "        if e in (phase_switch-1, phase_switch, epochs-1):\n",
    "            for name, net in nets.items():\n",
    "                w = net.input_2_output_connection.weights.ravel()\n",
    "                # Compute the angle in degrees between the weight vector w and pc1, where pc1 is the first principal component of the current input spike covariance\n",
    "                ang = _angle_deg(w, pc1)\n",
    "                # The magnitude (L2 norm) of the weight vector\n",
    "                print(f\"Epoch {e+1:03d} [{name}] angle(w, PC1) = {ang:6.2f} deg, |w|={np.linalg.norm(w):.3f}\")\n",
    "\n",
    "    # Print learned weights; DO NOT CHANGE\n",
    "    print(\"\\nFinal weight vectors:\")\n",
    "    for name, net in nets.items():\n",
    "        print(f\"{name:10s}: w = {net.input_2_output_connection.weights.ravel()}\")\n",
    "\n",
    "# =========================\n",
    "# Utility; DO NOT CHANGE\n",
    "# =========================\n",
    "def _delayed(arr, lag):\n",
    "    \"\"\"\n",
    "    Creates a time-shifted (delayed or advanced) version of a 1-D array, such as a spike train or signal. \n",
    "    I.e. shifts the signal forward or backward in time by lag timesteps and fills the missing values with zeros.\n",
    "    \"\"\"\n",
    "    y = np.zeros_like(arr)\n",
    "    T = len(arr)\n",
    "    if lag > 0:\n",
    "        y[lag:] = arr[:-lag]\n",
    "    elif lag < 0:\n",
    "        k = -lag \n",
    "        if k < T:\n",
    "            y[:T-k] = arr[k:]\n",
    "    else:\n",
    "        y[:] = arr\n",
    "    return y\n",
    "\n",
    "# =========================\n",
    "# Task B: Temporal causality\n",
    "# =========================\n",
    "def taskB_temporal_causality(epochs=60, T1=120, T2=420, seed=321,\n",
    "                             base_phase1=0.10, burst_phase1=0.60,\n",
    "                             base_phase2=0.08, burst_phase2=0.80,\n",
    "                             k_stdp_phase1=1, k_stdp_phase2=3):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    W0 = rng.uniform(-0.35, 0.35, size=(1, 2)) #Initialize Weights\n",
    "\n",
    "    def make_net(T=T1):\n",
    "        return SNN(W0.copy(), 2, 1, vdecay=0.5, vth=0.60, snn_timestep=T)\n",
    "\n",
    "    nets = { # Initialize Networks\n",
    "        'Hebb':       SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'Oja':        SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'Sejnowski':  SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'BCM':        SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "        'STDP':       SNN(W0.copy(), input_dimension=2, output_dimension=1, vdecay=0.5, vth=0.5, snn_timestep=T),\n",
    "    }\n",
    "    \n",
    "    # Define necessary objects and hyperparameters for each SNN\n",
    "\n",
    "    # Task-parameters; DO NOT CHANGE\n",
    "    phase_switch = epochs // 2\n",
    "    lag_gen = 2\n",
    "    teacher_lag = -lag_gen\n",
    "\n",
    "    print(\"\\n=== Task B: Temporal causality (who leads) ===\")\n",
    "    for e in range(epochs):\n",
    "        # Input data computation for task B; DO NOT CHANGE\n",
    "        in_phase2 = (e >= phase_switch)\n",
    "        T = T2 if in_phase2 else T1\n",
    "        base = base_phase2 if in_phase2 else base_phase1\n",
    "        burst = burst_phase2 if in_phase2 else burst_phase1\n",
    "        k_stdp = k_stdp_phase2 if in_phase2 else k_stdp_phase1\n",
    "\n",
    "        for net in nets.values():\n",
    "            net.snn_timestep = T\n",
    "        stdp.snn_timesteps = T\n",
    "        stdp.time = np.arange(0, T, 1)\n",
    "\n",
    "        lead = 1 if e < phase_switch else 2\n",
    "        X = gen_phase_spikes_temporal(T, lead=lead, lag=lag_gen, base=base, burst=burst, rng=rng)\n",
    "        y_out = _delayed(X[0], teacher_lag) if lead == 1 else _delayed(X[1], teacher_lag)\n",
    "\n",
    "        for _ in range(3):\n",
    "            # Todo: train your SNNs using step functions above\n",
    "\n",
    "        # Output weights and metrics at interesting points; DO NOT CHANGE\n",
    "        if e in (phase_switch-1, phase_switch, epochs-1):\n",
    "            print(f\"\\nEpoch {e+1:03d} (lead = x{lead})\")\n",
    "            for name, net in nets.items():\n",
    "                w = net.input_2_output_connection.weights.ravel()\n",
    "                pref = \"x1\" if w[0] > w[1] else \"x2\"\n",
    "                print(f\"{name:10s}: w = {w},  -> prefers {pref}\")\n",
    "\n",
    "    # DO NOT CHANGE\n",
    "    print(\"\\nFinal preference after Phase 1 then Phase 2:\")\n",
    "    for name, net in nets.items():\n",
    "        w = net.input_2_output_connection.weights.ravel()\n",
    "        pref = \"x1\" if w[0] > w[1] else \"x2\"\n",
    "        print(f\"{name:10s}: prefers {pref}\")\n",
    "\n",
    "# ===== Run Task A (feature tracking) =====\n",
    "taskA_compare_rules(epochs=80, T=60, seed=123)\n",
    "\n",
    "# ===== Run Task B (temporal causality) =====\n",
    "taskB_temporal_causality(epochs=60, seed=321)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 8c.\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8d — Conceptual Comparison\n",
    "\n",
    "In 3–5 sentences each, explain:\n",
    "* Hebbian instability: Why does plain Hebb lead to runaway excitation?\n",
    "* Normalization (Oja): How does Oja’s rule constrain this?\n",
    "Homeostatic thresholds (Sejnowski & BCM):\n",
    "* How does Sejnowski’s fixed threshold compare to BCM’s adaptive one?\n",
    "Relation to STDP:\n",
    "* How do these rate-based rules approximate pair-based or triplet-based STDP in time-averaged form?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 8d.\n",
    "\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9 – Reward‑Modulated STDP (R‑STDP) on a 2‑Arm Bandit\n",
    "\n",
    "Previously you saw **unsupervised** rules (Hebb / Oja) that move weights toward\n",
    "directions of *high variance* or *correlation* in the input.  \n",
    "In this question you add a **task** and a **reward**, and let the synapse decide whether a correlation was “good” or “bad”.\n",
    "\n",
    "The toy task is a **2-armed bandit** — the minimal RL problem — so that the\n",
    "math and code stay small while the ideas are exactly the same as in large-scale\n",
    "actor-critic / policy-gradient algorithms.\n",
    "\n",
    "The central challenge is the exploration-exploitation trade-off.\n",
    " \n",
    "- An agent must decide whether to exploit its current knowledge by choosing the arm with the highest estimated reward or to explore other arms that might have higher potential rewards but are currently less understood.\n",
    "\n",
    "- The problem is framed as a set of K arms (actions), where each arm's reward is drawn from a fixed but initially unknown probability distribution.\n",
    "\n",
    "- The agent's goal is to maximize its cumulative reward over a series of turns by learning which arm is the best and consistently choosing it.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Multi-armed_bandit\n",
    "\n",
    "**Goal.** Implement a tiny spiking network that learns to solve a simple **2‑armed bandit**\n",
    "task using a **reward‑modulated STDP** rule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "- Understand the difference between **Hebbian/Oja** learning and **reward‑modulated STDP**.\n",
    "- Implement a minimal **spiking policy** with 1 input neuron and 2 output neurons.\n",
    "- Train that policy with R‑STDP and interpret the learning curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9a. Environment: 2‑arm bandit\n",
    "\n",
    "- On each trial \\(t\\) you choose an action  \n",
    "  \\[\n",
    "  $a_t \\in \\{0,1\\}$.\n",
    "  \\]\n",
    "- **Arm 0** is the “better” arm:  \n",
    "  \\[\n",
    "  $R_t =\n",
    "    \\begin{cases}\n",
    "      +1 & \\text{with probability } p_{\\text{good}} \\\\\n",
    "      -1 & \\text{with probability } 1-p_{\\text{good}}\n",
    "    \\end{cases}$\n",
    "  \\]\n",
    "- **Arm 1** is worse: its success probability is \\($1-p_{\\text{good}}$\\).\n",
    "\n",
    "Key ideas:\n",
    "\n",
    "- There is **no state**, only a repeated choice → bandit, not full RL.\n",
    "- There is **stochastic reward**: even the good arm sometimes loses.\n",
    "- The optimal policy is simply “pick arm 0 almost all the time”, but the agent\n",
    "  does **not** know which arm is good at the start and must **explore**.\n",
    "\n",
    "You will plot:\n",
    "\n",
    "- A moving average of reward (fraction of wins).\n",
    "- An exponential moving average of **accuracy** (how often the agent picks the\n",
    "  actually-better arm).\n",
    "\n",
    "These curves tell you whether learning is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_global = np.random.default_rng(0)\n",
    "\n",
    "def bandit_step(action, p_good=0.6, rng=None):\n",
    "    \"\"\"One step of a 2‑arm bandit. Returns reward r ∈ {+1, −1}.\n",
    "    \n",
    "    Args:\n",
    "        action (int): Which arm to pull (0 or 1)\n",
    "        p_good (float): Probability of reward=+1 for arm 0 (default 0.6)\n",
    "        rng: Random number generator (optional)\n",
    "        \n",
    "    Returns:\n",
    "        int: Reward (+1 or -1)\n",
    "    \"\"\"\n",
    "    # Use global RNG if none provided\n",
    "    \n",
    "    # Get success probability based on which arm was chosen\n",
    "    # Arm 0 has p_good probability of reward\n",
    "    # Arm 1 has (1-p_good) probability of reward\n",
    "    \n",
    "    # Return +1 with probability p, else -1\n",
    "    return \n",
    "\n",
    "# quick check\n",
    "for a in [0, 1]:\n",
    "    rs = [bandit_step(a, p_good=0.7) for _ in range(1000)]\n",
    "    print(f\"Empirical mean reward for arm {a}: {np.mean(rs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 9b. Tiny SNN policy: 1 input → 2 outputs\n",
    "\n",
    "To keep the focus on plasticity, we use the smallest possible SNN:\n",
    "\n",
    "- One **always-spiking input neuron** (“context = I’m making a choice now”).\n",
    "  - You can think of its firing rate as fixed at 1 spike per trial, so “pre”\n",
    "    is always active.\n",
    "- Two **output neurons** corresponding to the two actions:\n",
    "  - Their synaptic weights from the input are \\($w_0$\\) and \\($w_1$\\).\n",
    "  - Higher weight → higher firing propensity → higher action probability.\n",
    "\n",
    "We turn these two weights into a **stochastic policy** via a softmax:\n",
    "\\[\n",
    "$\\pi(a = i) = \\frac{\\exp(w_i / \\text{temp})}\n",
    "                  {\\exp(w_0 / \\text{temp}) + \\exp(w_1 / \\text{temp})},\n",
    "\\quad i \\in \\{0,1\\}$.\n",
    "\\]\n",
    "\n",
    "- `temp` (temperature) controls **exploration**:\n",
    "  - High `temp` → weights are “blurred” → actions more random.\n",
    "  - Low `temp` → softmax sharper → the currently larger weight is chosen\n",
    "    almost greedily.\n",
    "\n",
    "This is conceptually the same as a **policy network** in RL, but with just\n",
    "1×2 weights and 2 spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Initial policy probs: [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "class TinyBanditSNN:\n",
    "    \"\"\"1‑input, 2‑output policy with R‑STDP‑style weight updates.\"\"\"\n",
    "    def __init__(self, lr=1e-2, temp=0.5):\n",
    "        self.w = np.zeros(2, dtype=float)\n",
    "        self.lr = float(lr)\n",
    "        self.temp = float(temp)\n",
    "\n",
    "    def policy(self):\n",
    "        \"\"\"Softmax over weights → action probabilities.\"\"\"\n",
    "        logits = self.w / self.temp\n",
    "        exps = np.exp(logits - logits.max())\n",
    "        return exps / exps.sum()\n",
    "\n",
    "    def act(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = rng_global\n",
    "        p = self.policy()\n",
    "        return 0 if rng.random() < p[0] else 1\n",
    "\n",
    "    def rstdp_update(self, action, reward):\n",
    "        \"\"\"Reward‑modulated STDP for chosen action.\n",
    "        \n",
    "        Args:\n",
    "            action: The action chosen (0 or 1)\n",
    "            reward: The reward received (+1 or -1)\n",
    "            \n",
    "        Updates:\n",
    "            Only the weight corresponding to the chosen action is modified.\n",
    "            The update is proportional to:\n",
    "            - The reward (positive = strengthen, negative = weaken)\n",
    "            - A quadratic term (1-w^2) that bounds weights to [-1,1]\n",
    "            \n",
    "        The quadratic term implements soft bounds on the weights:\n",
    "        - As w approaches +1 or -1, (1-w^2) approaches 0\n",
    "        - This prevents runaway weight growth while allowing exploration\n",
    "        \"\"\"\n",
    "        # Convert action to integer index\n",
    "        \n",
    "        # Convert reward to float \n",
    "                \n",
    "        # Update only the weight for the chosen action\n",
    "        # Multiply learning rate * reward * (1-w^2) term\n",
    "        \n",
    "        # Hard clip weights to [-1,1] for stability\n",
    "\n",
    "# quick check\n",
    "net = TinyBanditSNN(lr=1e-2, temp=0.5)\n",
    "print(\"Initial weights:\", net.w)\n",
    "print(\"Initial policy probs:\", net.policy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 9c. Training loop with R‑STDP\n",
    "\n",
    "Recall pure Hebbian / Oja-style updates:\n",
    "\n",
    "- **Hebb:** \\($\\Delta w \\propto \\text{pre} \\cdot \\text{post}$\\).\n",
    "- **Oja:** \\($\\Delta w = \\eta\\, y(\\mathbf{x} - y\\mathbf{w})$\\).\n",
    "\n",
    "Those rules *always* change the weight whenever pre and post are active.\n",
    "They do not know if that change helped or hurt the task.\n",
    "\n",
    "For **R-STDP** we introduce a **global reward signal** \\($R_t$\\) and gate the\n",
    "plasticity with it. Conceptually:\n",
    "\n",
    "1. During the trial, synapses build up an **eligibility trace**\n",
    "   \\($e_t \\sim \\text{pre} \\times \\text{post}$\\) — “this synapse was involved”.\n",
    "2. At the end of the trial a scalar **reward** \\($R_t$\\) arrives.\n",
    "3. The actual weight change is:\n",
    "   \\[\n",
    "   $\\Delta w \\propto (R_t - b) \\cdot e_t$,\n",
    "   \\]\n",
    "   where \\(b\\) is a **baseline** (running average of reward).\n",
    "\n",
    "In this bandit SNN:\n",
    "\n",
    "- Pre = 1 (always on input).\n",
    "- Post = 1 for the **chosen** output neuron only.\n",
    "- We update only the chosen synapse \\(w_a\\):\n",
    "  \\[\n",
    "  $\\Delta w_a = \\eta\\, (R_t - b)\\, e_t - \\lambda w_a$.\n",
    "  \\]\n",
    "  - If \\($R_t > b$\\) (better-than-expected reward) and \\($e_t > 0$\\):  \n",
    "    weight **increases** → action more likely next time.\n",
    "  - If \\($R_t < b$\\): weight **decreases** → action less likely.\n",
    "  - \\($-\\lambda w_a$\\) is a small **weight decay** that prevents divergence.\n",
    "\n",
    "The baseline \\(b\\) is updated slowly:\n",
    "\\[\n",
    "$b \\leftarrow (1-\\alpha_b)\\,b + \\alpha_b\\,R_t$,\n",
    "\\]\n",
    "so it tracks the long-term average reward and reduces gradient variance (exactly\n",
    "the idea of a “variance-reduced” policy gradient).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rstdp_bandit(T=2000, p_good=0.6, lr=1e-2, temp=0.5,\n",
    "                       ma_win=50, ema_alpha=0.01, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    net = TinyBanditSNN(lr=lr, temp=temp)\n",
    "\n",
    "    reward_ma = []\n",
    "    acc_ema   = []\n",
    "    buf = []\n",
    "    acc_val = 0.0\n",
    "\n",
    "    # Training loop over T trials\n",
    "    for t in range(T):\n",
    "        # Choose an action using the SNN's policy\n",
    "        \n",
    "        # Get reward from bandit (+1 or -1)\n",
    "               \n",
    "        # Update the network weights using R-STDP rule\n",
    "        \n",
    "        # Track moving average of rewards:\n",
    "        # Convert reward to binary (1=win, 0=loss) \n",
    "        \n",
    "        # Keep buffer at fixed window size\n",
    "        if len(buf) > ma_win:\n",
    "            buf.pop(0)\n",
    "            \n",
    "        # Compute average over window\n",
    "        reward_ma.append(sum(buf)/len(buf))\n",
    "\n",
    "        # Track exponential moving average of accuracy:\n",
    "        # correct = 1 if chose arm 0 (the better arm)\n",
    "        correct = 1 if a == 0 else 0\n",
    "        # Update EMA with new accuracy value\n",
    "        acc_val = (1 - ema_alpha) * acc_val + ema_alpha * correct\n",
    "        # Store current EMA value\n",
    "        acc_ema.append(acc_val)\n",
    "\n",
    "    return net, np.array(reward_ma), np.array(acc_ema)\n",
    "\n",
    "net, reward_ma, acc_ema = train_rstdp_bandit(T=2000, p_good=0.6, lr=1e-2, temp=0.5)\n",
    "print(\"Final weights:\", net.w)\n",
    "\n",
    "T_steps = len(reward_ma)\n",
    "plt.figure(figsize=(6, 2.8))\n",
    "plt.plot(range(T_steps), reward_ma, label='reward (50‑MA)')\n",
    "plt.plot(range(T_steps), acc_ema,   label='accuracy (EMA)')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlabel('trial'); plt.ylabel('value')\n",
    "plt.title('R‑STDP learning on a 2‑arm bandit')\n",
    "plt.grid(True); plt.legend(); plt.tight_layout();\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "W_vis = np.array([[net.w[0], 0.0],\n",
    "                  [0.0,      net.w[1]]])\n",
    "plt.imshow(W_vis, vmin=-1, vmax=1, cmap='bwr')\n",
    "plt.colorbar(label='weight')\n",
    "plt.xlabel('output neuron'); plt.ylabel('input channel')\n",
    "plt.title('Input→Output weights after R‑STDP')\n",
    "plt.tight_layout();\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 9d. Questions\n",
    "\n",
    "1. **Eligibility vs. reward.**\n",
    "   - In your implementation, what quantity corresponds to the **eligibility\n",
    "     trace**?\n",
    "   - What is the **global reward** signal here, and when does it arrive in the\n",
    "     trial?\n",
    "   - Explain in 2–3 sentences why splitting plasticity into “eligibility ×\n",
    "     reward” is biologically plausible (local synapse vs. global neuromodulator).\n",
    "\n",
    "2. **Compare to Oja’s rule.**\n",
    "   - Oja’s rule changes weights based only on the current input and neuron\n",
    "     activity; it has **no notion of task or reward**.\n",
    "   - R-STDP adds a **scalar, global** term \\($(R_t - b)$\\) that is *shared* by all\n",
    "     synapses but multiplied by their own local eligibility.\n",
    "   - Explain why this makes R-STDP a kind of **three-factor rule**:\n",
    "     \\[\n",
    "      $\\Delta w \\propto \\underbrace{\\text{pre}}_{\\text{local}}\n",
    "                        \\times \\underbrace{\\text{post}}_{\\text{local}}\n",
    "                        \\times \\underbrace{(R-b)}_{\\text{global}}$.\n",
    "     \\]\n",
    "     How is that closer to the idea of policy-gradient RL (REINFORCE) than Oja’s\n",
    "     purely unsupervised rule?\n",
    "\n",
    "3. **Effect of \\($p_{\\text{good}}$\\).**\n",
    "   - Run with `p_good = 0.8`, `0.6`, and `0.5`.\n",
    "   - When `p_good = 0.8`?\n",
    "   - When `p_good = 0.6`?\n",
    "   - When `p_good = 0.5`?\n",
    "\n",
    "     What should the optimal accuracy be in that case? How does your reward and\n",
    "     accuracy curve reflect that?\n",
    "\n",
    "4. **Exploration via temperature `temp`.**\n",
    "   - High `temp` ⇒ ?\n",
    "   - Low `temp` ⇒ ?\n",
    "   - Describe what happens to:\n",
    "     - the **speed** at which accuracy improves, and\n",
    "     - the **stability** of the final policy when you sweep `temp` from high to low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 9d. Answer\n",
    "<font color='red'>\n",
    "Double click to enter your response here.\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
